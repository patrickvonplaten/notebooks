{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to evaluate Longformer on TriviaQA using NLP",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMobmJFrxuYygHuUuXMD52/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/How_to_evaluate_Longformer_on_TriviaQA_using_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbNZdYkugq7-",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation of a model using ðŸ¤—nlp\n",
        "\n",
        "*This notebook shows how `nlp` can be leveraged to evaluate **Longformer** on **TriviaQA** .*\n",
        "\n",
        "- The [`nlp`](https://github.com/huggingface/nlp) library allows simple and intuitive access to nlp datasets and metrics.\n",
        "\n",
        "- **Longformer** is transformer-based model for long-range sequence modeling introduced by *Iz Beltagy, Matthew E. Peters, Arman Cohan* (see paper [here](https://arxiv.org/abs/2004.05150)) and can now be accessed via Transformers via the [docs](https://huggingface.co/transformers/model_doc/longformer.html).\n",
        "\n",
        "- **TriviaQA** is a reading comprehension dataset containing question-answer-evidence triplets (see paper here [here](https://homes.cs.washington.edu/~eunsol/papers/acl17jcwz.pdf))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckDfoClXj-mm",
        "colab_type": "text"
      },
      "source": [
        "We will evaluate a pretrained `LongformerForQuestionAnswering` model on the *validation* dataset of **TriviaQA**. Along the way, this notebook will show you how `nlp` can be used for effortless preprocessing of data and analysis of the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGg2btE2mY0v",
        "colab_type": "text"
      },
      "source": [
        "Alright! Let's start by installing the `nlp` library and loading *TriviaQA*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLb6vCflSqcI",
        "colab_type": "text"
      },
      "source": [
        "### Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXHkpUVuft4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install nlp\n",
        "!pip install -qq nlp==0.2.0\n",
        "\n",
        "# Make sure that we have a recent version of pyarrow in the session before we continue - otherwise reboot Colab to activate it\n",
        "import pyarrow\n",
        "if int(pyarrow.__version__.split('.')[1]) < 16:\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "!pip install -qq transformers==2.11.0\n",
        "\n",
        "import nlp\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mV2lN2fe3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATTENTION. Rerunning this command remove the cached trivia qa dataset completely \n",
        "!rm -rf /root/.cache/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVQCLkYbS0Nm",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning and preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpOqRdcjnaBT",
        "colab_type": "text"
      },
      "source": [
        "The total *TriviaQA* dataset has a size of 17 GB once processed.\n",
        "Downloading and preprocessing the dataset will take around *15 minutes*. â˜•\n",
        "Afterwards the data is serialized in *Arrow* format for quick reloading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusOKo5FgkYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_dataset = nlp.load_dataset(\"trivia_qa\", \"rc\", split=\"validation[:5%]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_LFkvD_sx9H",
        "colab_type": "text"
      },
      "source": [
        "First, let's get an overview of the dataset ðŸ§"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJTko97rwQGF",
        "colab_type": "code",
        "outputId": "b6c28652-0984-4d22-9e40-3c0b0472eb4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "validation_dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(schema: {'question': 'string', 'question_id': 'string', 'question_source': 'string', 'entity_pages': 'struct<doc_source: list<item: string>, filename: list<item: string>, title: list<item: string>, wiki_context: list<item: string>>', 'search_results': 'struct<description: list<item: string>, filename: list<item: string>, rank: list<item: int32>, title: list<item: string>, url: list<item: string>, search_context: list<item: string>>', 'answer': 'struct<aliases: list<item: string>, normalized_aliases: list<item: string>, matched_wiki_entity_name: string, normalized_matched_wiki_entity_name: string, normalized_value: string, type: string, value: string>'}, num_rows: 933)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHsmt1ULwTug",
        "colab_type": "text"
      },
      "source": [
        "5% of the validation data corresponds to 933 examples, which we can use as a good snapshot of the actual dataset and get be used to get familiar with the dataset.\n",
        "\n",
        "Let's check out the datatset's structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjAVcrAitsU5",
        "colab_type": "code",
        "outputId": "11fb6010-1a1b-4f15-dfe1-7120888b8bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "# check out schema\n",
        "validation_dataset.schema"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question: string not null\n",
              "question_id: string not null\n",
              "question_source: string not null\n",
              "entity_pages: struct<doc_source: list<item: string>, filename: list<item: string>, title: list<item: string>, wiki_context: list<item: string>> not null\n",
              "  child 0, doc_source: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 1, filename: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 2, title: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 3, wiki_context: list<item: string>\n",
              "      child 0, item: string\n",
              "search_results: struct<description: list<item: string>, filename: list<item: string>, rank: list<item: int32>, title: list<item: string>, url: list<item: string>, search_context: list<item: string>> not null\n",
              "  child 0, description: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 1, filename: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 2, rank: list<item: int32>\n",
              "      child 0, item: int32\n",
              "  child 3, title: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 4, url: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 5, search_context: list<item: string>\n",
              "      child 0, item: string\n",
              "answer: struct<aliases: list<item: string>, normalized_aliases: list<item: string>, matched_wiki_entity_name: string, normalized_matched_wiki_entity_name: string, normalized_value: string, type: string, value: string> not null\n",
              "  child 0, aliases: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 1, normalized_aliases: list<item: string>\n",
              "      child 0, item: string\n",
              "  child 2, matched_wiki_entity_name: string\n",
              "  child 3, normalized_matched_wiki_entity_name: string\n",
              "  child 4, normalized_value: string\n",
              "  child 5, type: string\n",
              "  child 6, value: string"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XqHiM5mt5t-",
        "colab_type": "text"
      },
      "source": [
        "Alright, quite a lot of entries here! For Questions Answering, all we need is the *question*, the *context* and the *answer*. \n",
        "\n",
        "The **question** is a single entry, so we keep it.\n",
        "\n",
        "Because *Longformer* was trained on the Wikipedia part of *TriviaQA*, we will use `validation_dataset[\"entity_pages\"][\"search_context\"]` as our **context**. \n",
        "\n",
        "We can also see that there are multiple entries for the **answer**. In this use case, we define a correct output of the model as one that is one of the answer aliases `validation_dataset[\"answer\"][\"aliases\"]`. Lastly, we also keep `validation_dataset[\"answer\"][\"normalized_value\"]`. All other columns can be disregarded. \n",
        "\n",
        "We apply the `.map()` function to map the dataset into the format as defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpEkZy_LvhEX",
        "colab_type": "code",
        "outputId": "32241e60-7850-4904-c878-1bbdad6178a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define the mapping function\n",
        "def format_dataset(example):\n",
        "    # the context might be comprised of multiple contexts => me merge them here\n",
        "    example[\"context\"] = \" \".join((\"\\n\".join(example[\"entity_pages\"][\"wiki_context\"])).split(\"\\n\"))\n",
        "    example[\"targets\"] = example[\"answer\"][\"aliases\"]\n",
        "    example[\"norm_target\"] = example[\"answer\"][\"normalized_value\"]\n",
        "    return example\n",
        "\n",
        "# map the dataset and throw out all unnecessary columns\n",
        "validation_dataset = validation_dataset.map(format_dataset, remove_columns=[\"search_results\", \"question_source\", \"entity_pages\", \"answer\", \"question_id\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "933it [00:01, 564.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRhh7AJrw3fM",
        "colab_type": "text"
      },
      "source": [
        "Now, we can check out a first example of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I730mW9wNeo",
        "colab_type": "code",
        "outputId": "e4ca13cf-a822-4dca-d2b4-13cdc78e1821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "validation_dataset[8]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': '',\n",
              " 'norm_target': 'basket ball',\n",
              " 'question': 'The Naismith Award is presented in which sport?',\n",
              " 'targets': ['Basketball',\n",
              "  'Basketball gear',\n",
              "  'Bball',\n",
              "  \"Boy's Basketball\",\n",
              "  'B Ball',\n",
              "  'Shoot hoops',\n",
              "  'Basketball parity worldwide',\n",
              "  \"Men's Basketball\",\n",
              "  'High school basketball',\n",
              "  'Basketball Worldwide',\n",
              "  'Basketball club',\n",
              "  'B-ball',\n",
              "  'Basket-ball',\n",
              "  'Basketball team',\n",
              "  'ðŸ€',\n",
              "  'Basketball rim',\n",
              "  'Basketballer',\n",
              "  'Rim (basketball)',\n",
              "  'Basket ball',\n",
              "  'Basketball net',\n",
              "  'Baksetball',\n",
              "  'Basketball player',\n",
              "  'Basket-Ball',\n",
              "  \"Women's hoops\",\n",
              "  \"Men's basketball\",\n",
              "  'BasketBall',\n",
              "  'Basketball Parity Worldwide',\n",
              "  'Basket Ball',\n",
              "  'Baketball',\n",
              "  'Basketball Player',\n",
              "  'B ball',\n",
              "  'Unicycle basketball']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqcviRfJw-3M",
        "colab_type": "text"
      },
      "source": [
        "Great ðŸ™‚. That's exactly, the structure we wanted! Some examples might have an empty context so we will filter those examples out.\n",
        "For this we can use the convenient `.filter()` function of `nlp`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0vSycFKxc0O",
        "colab_type": "code",
        "outputId": "133831fb-d416-4669-a08a-b5f9a51deb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "validation_dataset = validation_dataset.filter(lambda x: len(x[\"context\"]) > 0)\n",
        "# check out how many samples are left\n",
        "validation_dataset"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(schema: {'question': 'string', 'context': 'string', 'targets': 'list<item: string>', 'norm_target': 'string'}, num_rows: 467)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMh8EvQoxsrF",
        "colab_type": "text"
      },
      "source": [
        "Looks like more or less half of our examples have no context and are now filtered out. Let's think about the evaluation on *Longformer* now. \n",
        "\n",
        "*Longformer* is able to process inputs of up to a length of **4096** tokens. As a rule of thumb, 4 is the average number of characters per word piece. Therefore, it is a good idea to check for how many examples, the *question* + *context* exceeds 4 * 4096 characters.\n",
        "Again we can apply the convenient `.map()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ebRyrOmy4br",
        "colab_type": "code",
        "outputId": "ac8edb9e-e566-4cce-e914-be9e50e39a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"\\n\\nLength for each example\")\n",
        "print(30 * \"=\")\n",
        "\n",
        "# length for each example\n",
        "validation_dataset.map(lambda x, i: print(f\"Id: {i} - Question Length: {len(x['question'])} - context Length: {len(x['context'])}\"), with_indices=True)\n",
        "print(30 * \"=\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Num examples larger than 4 * 4096 characters: \")\n",
        "# filter out examples smaller than 4 * 4096\n",
        "short_validation_dataset = validation_dataset.filter(lambda x: (len(x['question']) + len(x['context'])) < 4 * 4096)\n",
        "short_validation_dataset\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "207it [00:00, 1071.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Length for each example\n",
            "==============================\n",
            "Id: 0 - Question Length: 48 - context Length: 87872\n",
            "Id: 0 - Question Length: 48 - context Length: 87872\n",
            "Id: 0 - Question Length: 48 - context Length: 87872\n",
            "Id: 1 - Question Length: 85 - context Length: 39997\n",
            "Id: 2 - Question Length: 146 - context Length: 22353\n",
            "Id: 3 - Question Length: 114 - context Length: 73891\n",
            "Id: 4 - Question Length: 58 - context Length: 345\n",
            "Id: 5 - Question Length: 80 - context Length: 36373\n",
            "Id: 6 - Question Length: 68 - context Length: 1410\n",
            "Id: 7 - Question Length: 68 - context Length: 115858\n",
            "Id: 8 - Question Length: 81 - context Length: 1404\n",
            "Id: 9 - Question Length: 83 - context Length: 65529\n",
            "Id: 10 - Question Length: 75 - context Length: 32034\n",
            "Id: 11 - Question Length: 59 - context Length: 24511\n",
            "Id: 12 - Question Length: 111 - context Length: 46362\n",
            "Id: 13 - Question Length: 79 - context Length: 26408\n",
            "Id: 14 - Question Length: 190 - context Length: 52829\n",
            "Id: 15 - Question Length: 130 - context Length: 28293\n",
            "Id: 16 - Question Length: 70 - context Length: 56746\n",
            "Id: 17 - Question Length: 226 - context Length: 40032\n",
            "Id: 18 - Question Length: 225 - context Length: 57970\n",
            "Id: 19 - Question Length: 192 - context Length: 59116\n",
            "Id: 20 - Question Length: 135 - context Length: 51053\n",
            "Id: 21 - Question Length: 54 - context Length: 7853\n",
            "Id: 22 - Question Length: 38 - context Length: 26477\n",
            "Id: 23 - Question Length: 44 - context Length: 30986\n",
            "Id: 24 - Question Length: 39 - context Length: 33277\n",
            "Id: 25 - Question Length: 77 - context Length: 76046\n",
            "Id: 26 - Question Length: 43 - context Length: 55292\n",
            "Id: 27 - Question Length: 40 - context Length: 38445\n",
            "Id: 28 - Question Length: 84 - context Length: 49376\n",
            "Id: 29 - Question Length: 54 - context Length: 57495\n",
            "Id: 30 - Question Length: 63 - context Length: 14856\n",
            "Id: 31 - Question Length: 30 - context Length: 4253\n",
            "Id: 32 - Question Length: 41 - context Length: 49851\n",
            "Id: 33 - Question Length: 57 - context Length: 59303\n",
            "Id: 34 - Question Length: 97 - context Length: 12432\n",
            "Id: 35 - Question Length: 44 - context Length: 22585\n",
            "Id: 36 - Question Length: 135 - context Length: 14071\n",
            "Id: 37 - Question Length: 145 - context Length: 36834\n",
            "Id: 38 - Question Length: 81 - context Length: 100868\n",
            "Id: 39 - Question Length: 66 - context Length: 68597\n",
            "Id: 40 - Question Length: 100 - context Length: 39631\n",
            "Id: 41 - Question Length: 89 - context Length: 127757\n",
            "Id: 42 - Question Length: 139 - context Length: 7546\n",
            "Id: 43 - Question Length: 83 - context Length: 58060\n",
            "Id: 44 - Question Length: 55 - context Length: 21885\n",
            "Id: 45 - Question Length: 80 - context Length: 29993\n",
            "Id: 46 - Question Length: 24 - context Length: 9425\n",
            "Id: 47 - Question Length: 187 - context Length: 63535\n",
            "Id: 48 - Question Length: 80 - context Length: 7274\n",
            "Id: 49 - Question Length: 69 - context Length: 31886\n",
            "Id: 50 - Question Length: 61 - context Length: 92734\n",
            "Id: 51 - Question Length: 46 - context Length: 2458\n",
            "Id: 52 - Question Length: 49 - context Length: 33175\n",
            "Id: 53 - Question Length: 55 - context Length: 27460\n",
            "Id: 54 - Question Length: 69 - context Length: 95689\n",
            "Id: 55 - Question Length: 60 - context Length: 80213\n",
            "Id: 56 - Question Length: 54 - context Length: 40965\n",
            "Id: 57 - Question Length: 47 - context Length: 8346\n",
            "Id: 58 - Question Length: 58 - context Length: 66514\n",
            "Id: 59 - Question Length: 57 - context Length: 43083\n",
            "Id: 60 - Question Length: 51 - context Length: 823\n",
            "Id: 61 - Question Length: 48 - context Length: 14555\n",
            "Id: 62 - Question Length: 55 - context Length: 137066\n",
            "Id: 63 - Question Length: 64 - context Length: 91380\n",
            "Id: 64 - Question Length: 79 - context Length: 115129\n",
            "Id: 65 - Question Length: 100 - context Length: 34736\n",
            "Id: 66 - Question Length: 57 - context Length: 11291\n",
            "Id: 67 - Question Length: 80 - context Length: 2339\n",
            "Id: 68 - Question Length: 75 - context Length: 49982\n",
            "Id: 69 - Question Length: 116 - context Length: 16115\n",
            "Id: 70 - Question Length: 81 - context Length: 62202\n",
            "Id: 71 - Question Length: 45 - context Length: 71824\n",
            "Id: 72 - Question Length: 70 - context Length: 23077\n",
            "Id: 73 - Question Length: 50 - context Length: 19289\n",
            "Id: 74 - Question Length: 49 - context Length: 15348\n",
            "Id: 75 - Question Length: 52 - context Length: 40966\n",
            "Id: 76 - Question Length: 52 - context Length: 92451\n",
            "Id: 77 - Question Length: 96 - context Length: 5310\n",
            "Id: 78 - Question Length: 42 - context Length: 66143\n",
            "Id: 79 - Question Length: 38 - context Length: 9151\n",
            "Id: 80 - Question Length: 48 - context Length: 95128\n",
            "Id: 81 - Question Length: 57 - context Length: 67669\n",
            "Id: 82 - Question Length: 43 - context Length: 3521\n",
            "Id: 83 - Question Length: 47 - context Length: 27681\n",
            "Id: 84 - Question Length: 38 - context Length: 72219\n",
            "Id: 85 - Question Length: 59 - context Length: 5469\n",
            "Id: 86 - Question Length: 37 - context Length: 18247\n",
            "Id: 87 - Question Length: 71 - context Length: 57522\n",
            "Id: 88 - Question Length: 50 - context Length: 49267\n",
            "Id: 89 - Question Length: 46 - context Length: 1017\n",
            "Id: 90 - Question Length: 33 - context Length: 8851\n",
            "Id: 91 - Question Length: 46 - context Length: 18591\n",
            "Id: 92 - Question Length: 65 - context Length: 42637\n",
            "Id: 93 - Question Length: 52 - context Length: 32864\n",
            "Id: 94 - Question Length: 43 - context Length: 23118\n",
            "Id: 95 - Question Length: 33 - context Length: 44691\n",
            "Id: 96 - Question Length: 51 - context Length: 42435\n",
            "Id: 97 - Question Length: 55 - context Length: 38324\n",
            "Id: 98 - Question Length: 50 - context Length: 4771\n",
            "Id: 99 - Question Length: 84 - context Length: 45955\n",
            "Id: 100 - Question Length: 56 - context Length: 30291\n",
            "Id: 101 - Question Length: 54 - context Length: 45300\n",
            "Id: 102 - Question Length: 70 - context Length: 12214\n",
            "Id: 103 - Question Length: 64 - context Length: 55067\n",
            "Id: 104 - Question Length: 68 - context Length: 1849\n",
            "Id: 105 - Question Length: 40 - context Length: 51632\n",
            "Id: 106 - Question Length: 47 - context Length: 87972\n",
            "Id: 107 - Question Length: 29 - context Length: 22272\n",
            "Id: 108 - Question Length: 48 - context Length: 23099\n",
            "Id: 109 - Question Length: 67 - context Length: 15243\n",
            "Id: 110 - Question Length: 67 - context Length: 54203\n",
            "Id: 111 - Question Length: 62 - context Length: 5865\n",
            "Id: 112 - Question Length: 53 - context Length: 4787\n",
            "Id: 113 - Question Length: 58 - context Length: 25293\n",
            "Id: 114 - Question Length: 76 - context Length: 112048\n",
            "Id: 115 - Question Length: 26 - context Length: 99217\n",
            "Id: 116 - Question Length: 65 - context Length: 73779\n",
            "Id: 117 - Question Length: 33 - context Length: 3724\n",
            "Id: 118 - Question Length: 51 - context Length: 414\n",
            "Id: 119 - Question Length: 51 - context Length: 22596\n",
            "Id: 120 - Question Length: 69 - context Length: 28220\n",
            "Id: 121 - Question Length: 63 - context Length: 12467\n",
            "Id: 122 - Question Length: 49 - context Length: 3008\n",
            "Id: 123 - Question Length: 69 - context Length: 22600\n",
            "Id: 124 - Question Length: 51 - context Length: 50618\n",
            "Id: 125 - Question Length: 75 - context Length: 15492\n",
            "Id: 126 - Question Length: 70 - context Length: 36803\n",
            "Id: 127 - Question Length: 86 - context Length: 183133\n",
            "Id: 128 - Question Length: 58 - context Length: 6897\n",
            "Id: 129 - Question Length: 76 - context Length: 43265\n",
            "Id: 130 - Question Length: 65 - context Length: 137325\n",
            "Id: 131 - Question Length: 66 - context Length: 7255\n",
            "Id: 132 - Question Length: 93 - context Length: 124858\n",
            "Id: 133 - Question Length: 64 - context Length: 4308\n",
            "Id: 134 - Question Length: 62 - context Length: 11893\n",
            "Id: 135 - Question Length: 75 - context Length: 12055\n",
            "Id: 136 - Question Length: 68 - context Length: 13871\n",
            "Id: 137 - Question Length: 72 - context Length: 4270\n",
            "Id: 138 - Question Length: 56 - context Length: 40063\n",
            "Id: 139 - Question Length: 53 - context Length: 24092\n",
            "Id: 140 - Question Length: 54 - context Length: 56746\n",
            "Id: 141 - Question Length: 74 - context Length: 15914\n",
            "Id: 142 - Question Length: 65 - context Length: 91609\n",
            "Id: 143 - Question Length: 34 - context Length: 43813\n",
            "Id: 144 - Question Length: 70 - context Length: 49361\n",
            "Id: 145 - Question Length: 59 - context Length: 15933\n",
            "Id: 146 - Question Length: 59 - context Length: 64074\n",
            "Id: 147 - Question Length: 46 - context Length: 2510\n",
            "Id: 148 - Question Length: 119 - context Length: 105341\n",
            "Id: 149 - Question Length: 70 - context Length: 12929\n",
            "Id: 150 - Question Length: 41 - context Length: 126298\n",
            "Id: 151 - Question Length: 93 - context Length: 2280\n",
            "Id: 152 - Question Length: 34 - context Length: 25084\n",
            "Id: 153 - Question Length: 65 - context Length: 85861\n",
            "Id: 154 - Question Length: 49 - context Length: 70974\n",
            "Id: 155 - Question Length: 59 - context Length: 48810\n",
            "Id: 156 - Question Length: 47 - context Length: 3175\n",
            "Id: 157 - Question Length: 66 - context Length: 84436\n",
            "Id: 158 - Question Length: 37 - context Length: 16375\n",
            "Id: 159 - Question Length: 89 - context Length: 5393\n",
            "Id: 160 - Question Length: 49 - context Length: 17210\n",
            "Id: 161 - Question Length: 88 - context Length: 20128\n",
            "Id: 162 - Question Length: 95 - context Length: 11473\n",
            "Id: 163 - Question Length: 61 - context Length: 77619\n",
            "Id: 164 - Question Length: 59 - context Length: 79722\n",
            "Id: 165 - Question Length: 62 - context Length: 64718\n",
            "Id: 166 - Question Length: 65 - context Length: 1119\n",
            "Id: 167 - Question Length: 98 - context Length: 97798\n",
            "Id: 168 - Question Length: 29 - context Length: 40250\n",
            "Id: 169 - Question Length: 40 - context Length: 148208\n",
            "Id: 170 - Question Length: 59 - context Length: 13763\n",
            "Id: 171 - Question Length: 65 - context Length: 3338\n",
            "Id: 172 - Question Length: 43 - context Length: 27856\n",
            "Id: 173 - Question Length: 65 - context Length: 54483\n",
            "Id: 174 - Question Length: 60 - context Length: 11299\n",
            "Id: 175 - Question Length: 109 - context Length: 331078\n",
            "Id: 176 - Question Length: 46 - context Length: 114523\n",
            "Id: 177 - Question Length: 104 - context Length: 33933\n",
            "Id: 178 - Question Length: 60 - context Length: 48869\n",
            "Id: 179 - Question Length: 96 - context Length: 32569\n",
            "Id: 180 - Question Length: 51 - context Length: 29176\n",
            "Id: 181 - Question Length: 39 - context Length: 4004\n",
            "Id: 182 - Question Length: 60 - context Length: 114038\n",
            "Id: 183 - Question Length: 93 - context Length: 127480\n",
            "Id: 184 - Question Length: 66 - context Length: 91607\n",
            "Id: 185 - Question Length: 72 - context Length: 2196\n",
            "Id: 186 - Question Length: 86 - context Length: 14021\n",
            "Id: 187 - Question Length: 71 - context Length: 17171\n",
            "Id: 188 - Question Length: 61 - context Length: 51173\n",
            "Id: 189 - Question Length: 51 - context Length: 95689\n",
            "Id: 190 - Question Length: 55 - context Length: 67449\n",
            "Id: 191 - Question Length: 51 - context Length: 1837\n",
            "Id: 192 - Question Length: 74 - context Length: 80462\n",
            "Id: 193 - Question Length: 53 - context Length: 46131\n",
            "Id: 194 - Question Length: 82 - context Length: 20357\n",
            "Id: 195 - Question Length: 63 - context Length: 79823\n",
            "Id: 196 - Question Length: 55 - context Length: 43998\n",
            "Id: 197 - Question Length: 68 - context Length: 66836\n",
            "Id: 198 - Question Length: 69 - context Length: 27240\n",
            "Id: 199 - Question Length: 55 - context Length: 7452\n",
            "Id: 200 - Question Length: 45 - context Length: 52445\n",
            "Id: 201 - Question Length: 27 - context Length: 13281\n",
            "Id: 202 - Question Length: 86 - context Length: 144346\n",
            "Id: 203 - Question Length: 39 - context Length: 64464\n",
            "Id: 204 - Question Length: 39 - context Length: 150230\n",
            "Id: 205 - Question Length: 45 - context Length: 126888\n",
            "Id: 206 - Question Length: 41 - context Length: 28775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "338it [00:00, 634.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Id: 207 - Question Length: 59 - context Length: 39631\n",
            "Id: 208 - Question Length: 93 - context Length: 23574\n",
            "Id: 209 - Question Length: 51 - context Length: 22489\n",
            "Id: 210 - Question Length: 50 - context Length: 78665\n",
            "Id: 211 - Question Length: 59 - context Length: 25629\n",
            "Id: 212 - Question Length: 82 - context Length: 174487\n",
            "Id: 213 - Question Length: 109 - context Length: 16814\n",
            "Id: 214 - Question Length: 60 - context Length: 237243\n",
            "Id: 215 - Question Length: 43 - context Length: 166433\n",
            "Id: 216 - Question Length: 56 - context Length: 105678\n",
            "Id: 217 - Question Length: 57 - context Length: 86628\n",
            "Id: 218 - Question Length: 79 - context Length: 115092\n",
            "Id: 219 - Question Length: 85 - context Length: 226600\n",
            "Id: 220 - Question Length: 66 - context Length: 123074\n",
            "Id: 221 - Question Length: 54 - context Length: 144413\n",
            "Id: 222 - Question Length: 126 - context Length: 83264\n",
            "Id: 223 - Question Length: 72 - context Length: 79295\n",
            "Id: 224 - Question Length: 52 - context Length: 12264\n",
            "Id: 225 - Question Length: 76 - context Length: 37495\n",
            "Id: 226 - Question Length: 91 - context Length: 4532\n",
            "Id: 227 - Question Length: 84 - context Length: 122248\n",
            "Id: 228 - Question Length: 54 - context Length: 24062\n",
            "Id: 229 - Question Length: 43 - context Length: 57187\n",
            "Id: 230 - Question Length: 38 - context Length: 42894\n",
            "Id: 231 - Question Length: 66 - context Length: 30129\n",
            "Id: 232 - Question Length: 61 - context Length: 18605\n",
            "Id: 233 - Question Length: 109 - context Length: 126892\n",
            "Id: 234 - Question Length: 85 - context Length: 59900\n",
            "Id: 235 - Question Length: 45 - context Length: 27902\n",
            "Id: 236 - Question Length: 98 - context Length: 48489\n",
            "Id: 237 - Question Length: 87 - context Length: 38068\n",
            "Id: 238 - Question Length: 59 - context Length: 6076\n",
            "Id: 239 - Question Length: 104 - context Length: 145320\n",
            "Id: 240 - Question Length: 104 - context Length: 43858\n",
            "Id: 241 - Question Length: 51 - context Length: 24311\n",
            "Id: 242 - Question Length: 70 - context Length: 59374\n",
            "Id: 243 - Question Length: 40 - context Length: 31845\n",
            "Id: 244 - Question Length: 88 - context Length: 52759\n",
            "Id: 245 - Question Length: 68 - context Length: 24911\n",
            "Id: 246 - Question Length: 64 - context Length: 47994\n",
            "Id: 247 - Question Length: 32 - context Length: 91052\n",
            "Id: 248 - Question Length: 55 - context Length: 59945\n",
            "Id: 249 - Question Length: 61 - context Length: 10927\n",
            "Id: 250 - Question Length: 38 - context Length: 22880\n",
            "Id: 251 - Question Length: 53 - context Length: 67361\n",
            "Id: 252 - Question Length: 71 - context Length: 44960\n",
            "Id: 253 - Question Length: 90 - context Length: 100864\n",
            "Id: 254 - Question Length: 42 - context Length: 91311\n",
            "Id: 255 - Question Length: 45 - context Length: 75054\n",
            "Id: 256 - Question Length: 22 - context Length: 48062\n",
            "Id: 257 - Question Length: 63 - context Length: 59900\n",
            "Id: 258 - Question Length: 64 - context Length: 53754\n",
            "Id: 259 - Question Length: 45 - context Length: 45796\n",
            "Id: 260 - Question Length: 86 - context Length: 178078\n",
            "Id: 261 - Question Length: 65 - context Length: 78199\n",
            "Id: 262 - Question Length: 101 - context Length: 37610\n",
            "Id: 263 - Question Length: 63 - context Length: 42176\n",
            "Id: 264 - Question Length: 61 - context Length: 172066\n",
            "Id: 265 - Question Length: 68 - context Length: 67944\n",
            "Id: 266 - Question Length: 87 - context Length: 45421\n",
            "Id: 267 - Question Length: 65 - context Length: 35271\n",
            "Id: 268 - Question Length: 54 - context Length: 63463\n",
            "Id: 269 - Question Length: 88 - context Length: 62401\n",
            "Id: 270 - Question Length: 56 - context Length: 22766\n",
            "Id: 271 - Question Length: 95 - context Length: 110695\n",
            "Id: 272 - Question Length: 62 - context Length: 42609\n",
            "Id: 273 - Question Length: 111 - context Length: 80517\n",
            "Id: 274 - Question Length: 42 - context Length: 39967\n",
            "Id: 275 - Question Length: 75 - context Length: 83861\n",
            "Id: 276 - Question Length: 56 - context Length: 13756\n",
            "Id: 277 - Question Length: 43 - context Length: 99450\n",
            "Id: 278 - Question Length: 108 - context Length: 31179\n",
            "Id: 279 - Question Length: 46 - context Length: 51632\n",
            "Id: 280 - Question Length: 56 - context Length: 18733\n",
            "Id: 281 - Question Length: 77 - context Length: 226242\n",
            "Id: 282 - Question Length: 90 - context Length: 110271\n",
            "Id: 283 - Question Length: 88 - context Length: 63907\n",
            "Id: 284 - Question Length: 58 - context Length: 49186\n",
            "Id: 285 - Question Length: 41 - context Length: 118004\n",
            "Id: 286 - Question Length: 50 - context Length: 138102\n",
            "Id: 287 - Question Length: 156 - context Length: 41307\n",
            "Id: 288 - Question Length: 55 - context Length: 83861\n",
            "Id: 289 - Question Length: 81 - context Length: 34020\n",
            "Id: 290 - Question Length: 103 - context Length: 12285\n",
            "Id: 291 - Question Length: 100 - context Length: 81236\n",
            "Id: 292 - Question Length: 130 - context Length: 9420\n",
            "Id: 293 - Question Length: 76 - context Length: 52178\n",
            "Id: 294 - Question Length: 79 - context Length: 10376\n",
            "Id: 295 - Question Length: 71 - context Length: 73235\n",
            "Id: 296 - Question Length: 98 - context Length: 95143\n",
            "Id: 297 - Question Length: 46 - context Length: 2585\n",
            "Id: 298 - Question Length: 67 - context Length: 32215\n",
            "Id: 299 - Question Length: 119 - context Length: 67665\n",
            "Id: 300 - Question Length: 43 - context Length: 59243\n",
            "Id: 301 - Question Length: 113 - context Length: 43066\n",
            "Id: 302 - Question Length: 72 - context Length: 17753\n",
            "Id: 303 - Question Length: 60 - context Length: 18879\n",
            "Id: 304 - Question Length: 51 - context Length: 3491\n",
            "Id: 305 - Question Length: 65 - context Length: 56746\n",
            "Id: 306 - Question Length: 54 - context Length: 184822\n",
            "Id: 307 - Question Length: 80 - context Length: 45955\n",
            "Id: 308 - Question Length: 109 - context Length: 17900\n",
            "Id: 309 - Question Length: 144 - context Length: 471\n",
            "Id: 310 - Question Length: 65 - context Length: 3878\n",
            "Id: 311 - Question Length: 55 - context Length: 32814\n",
            "Id: 312 - Question Length: 35 - context Length: 9293\n",
            "Id: 313 - Question Length: 70 - context Length: 298039\n",
            "Id: 314 - Question Length: 56 - context Length: 19606\n",
            "Id: 315 - Question Length: 66 - context Length: 83103\n",
            "Id: 316 - Question Length: 54 - context Length: 26836\n",
            "Id: 317 - Question Length: 97 - context Length: 57241\n",
            "Id: 318 - Question Length: 88 - context Length: 72136\n",
            "Id: 319 - Question Length: 50 - context Length: 42021\n",
            "Id: 320 - Question Length: 52 - context Length: 61062\n",
            "Id: 321 - Question Length: 54 - context Length: 49625\n",
            "Id: 322 - Question Length: 49 - context Length: 22166\n",
            "Id: 323 - Question Length: 32 - context Length: 29483\n",
            "Id: 324 - Question Length: 44 - context Length: 193267\n",
            "Id: 325 - Question Length: 106 - context Length: 134224\n",
            "Id: 326 - Question Length: 61 - context Length: 30247\n",
            "Id: 327 - Question Length: 150 - context Length: 31512\n",
            "Id: 328 - Question Length: 47 - context Length: 44243\n",
            "Id: 329 - Question Length: 73 - context Length: 13588\n",
            "Id: 330 - Question Length: 95 - context Length: 80783\n",
            "Id: 331 - Question Length: 39 - context Length: 6683\n",
            "Id: 332 - Question Length: 35 - context Length: 2280\n",
            "Id: 333 - Question Length: 48 - context Length: 45312\n",
            "Id: 334 - Question Length: 90 - context Length: 74384\n",
            "Id: 335 - Question Length: 50 - context Length: 110388\n",
            "Id: 336 - Question Length: 66 - context Length: 19396\n",
            "Id: 337 - Question Length: 92 - context Length: 69589\n",
            "Id: 338 - Question Length: 110 - context Length: 31360\n",
            "Id: 339 - Question Length: 48 - context Length: 9935\n",
            "Id: 340 - Question Length: 66 - context Length: 1093\n",
            "Id: 341 - Question Length: 43 - context Length: 25581\n",
            "Id: 342 - Question Length: 39 - context Length: 20245\n",
            "Id: 343 - Question Length: 145 - context Length: 10132\n",
            "Id: 344 - Question Length: 64 - context Length: 13515\n",
            "Id: 345 - Question Length: 74 - context Length: 13367\n",
            "Id: 346 - Question Length: 60 - context Length: 18909\n",
            "Id: 347 - Question Length: 57 - context Length: 3077\n",
            "Id: 348 - Question Length: 67 - context Length: 4207\n",
            "Id: 349 - Question Length: 95 - context Length: 165934\n",
            "Id: 350 - Question Length: 147 - context Length: 25866\n",
            "Id: 351 - Question Length: 52 - context Length: 23725\n",
            "Id: 352 - Question Length: 62 - context Length: 8964\n",
            "Id: 353 - Question Length: 166 - context Length: 166560\n",
            "Id: 354 - Question Length: 129 - context Length: 64248\n",
            "Id: 355 - Question Length: 66 - context Length: 24626\n",
            "Id: 356 - Question Length: 139 - context Length: 52759\n",
            "Id: 357 - Question Length: 43 - context Length: 5569\n",
            "Id: 358 - Question Length: 65 - context Length: 27749\n",
            "Id: 359 - Question Length: 67 - context Length: 7628\n",
            "Id: 360 - Question Length: 58 - context Length: 22349\n",
            "Id: 361 - Question Length: 76 - context Length: 131463\n",
            "Id: 362 - Question Length: 88 - context Length: 84891\n",
            "Id: 363 - Question Length: 66 - context Length: 8608\n",
            "Id: 364 - Question Length: 130 - context Length: 25430\n",
            "Id: 365 - Question Length: 84 - context Length: 12971\n",
            "Id: 366 - Question Length: 49 - context Length: 62752\n",
            "Id: 367 - Question Length: 60 - context Length: 79336\n",
            "Id: 368 - Question Length: 76 - context Length: 5972\n",
            "Id: 369 - Question Length: 107 - context Length: 233001\n",
            "Id: 370 - Question Length: 66 - context Length: 25882\n",
            "Id: 371 - Question Length: 60 - context Length: 11217\n",
            "Id: 372 - Question Length: 38 - context Length: 29654\n",
            "Id: 373 - Question Length: 71 - context Length: 29426\n",
            "Id: 374 - Question Length: 61 - context Length: 48313\n",
            "Id: 375 - Question Length: 51 - context Length: 114534\n",
            "Id: 376 - Question Length: 63 - context Length: 36755\n",
            "Id: 377 - Question Length: 47 - context Length: 19432\n",
            "Id: 378 - Question Length: 98 - context Length: 19096\n",
            "Id: 379 - Question Length: 58 - context Length: 48324\n",
            "Id: 380 - Question Length: 73 - context Length: 9090\n",
            "Id: 381 - Question Length: 57 - context Length: 3691\n",
            "Id: 382 - Question Length: 59 - context Length: 27500\n",
            "Id: 383 - Question Length: 50 - context Length: 16650\n",
            "Id: 384 - Question Length: 75 - context Length: 27075\n",
            "Id: 385 - Question Length: 64 - context Length: 36567\n",
            "Id: 386 - Question Length: 75 - context Length: 15886\n",
            "Id: 387 - Question Length: 41 - context Length: 12822\n",
            "Id: 388 - Question Length: 63 - context Length: 67636\n",
            "Id: 389 - Question Length: 51 - context Length: 46142\n",
            "Id: 390 - Question Length: 65 - context Length: 63176\n",
            "Id: 391 - Question Length: 115 - context Length: 120518\n",
            "Id: 392 - Question Length: 36 - context Length: 54760\n",
            "Id: 393 - Question Length: 78 - context Length: 23411\n",
            "Id: 394 - Question Length: 35 - context Length: 121056\n",
            "Id: 395 - Question Length: 53 - context Length: 12420\n",
            "Id: 396 - Question Length: 75 - context Length: 35544\n",
            "Id: 397 - Question Length: 104 - context Length: 19670\n",
            "Id: 398 - Question Length: 44 - context Length: 146053\n",
            "Id: 399 - Question Length: 49 - context Length: 15733\n",
            "Id: 400 - Question Length: 78 - context Length: 24532\n",
            "Id: 401 - Question Length: 81 - context Length: 68624\n",
            "Id: 402 - Question Length: 67 - context Length: 27813\n",
            "Id: 403 - Question Length: 83 - context Length: 64110\n",
            "Id: 404 - Question Length: 51 - context Length: 75362\n",
            "Id: 405 - Question Length: 73 - context Length: 17332\n",
            "Id: 406 - Question Length: 135 - context Length: 34669\n",
            "Id: 407 - Question Length: 56 - context Length: 21737\n",
            "Id: 408 - Question Length: 56 - context Length: 209485\n",
            "Id: 409 - Question Length: 58 - context Length: 6125\n",
            "Id: 410 - Question Length: 125 - context Length: 109064\n",
            "Id: 411 - Question Length: 122 - context Length: 62180\n",
            "Id: 412 - Question Length: 71 - context Length: 80008\n",
            "Id: 413 - Question Length: 89 - context Length: 59397\n",
            "Id: 414 - Question Length: 38 - context Length: 69228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "467it [00:00, 760.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Id: 415 - Question Length: 55 - context Length: 62348\n",
            "Id: 416 - Question Length: 54 - context Length: 27761\n",
            "Id: 417 - Question Length: 29 - context Length: 109259\n",
            "Id: 418 - Question Length: 28 - context Length: 130367\n",
            "Id: 419 - Question Length: 27 - context Length: 31985\n",
            "Id: 420 - Question Length: 90 - context Length: 16250\n",
            "Id: 421 - Question Length: 48 - context Length: 7822\n",
            "Id: 422 - Question Length: 57 - context Length: 3912\n",
            "Id: 423 - Question Length: 40 - context Length: 64161\n",
            "Id: 424 - Question Length: 75 - context Length: 43874\n",
            "Id: 425 - Question Length: 116 - context Length: 110238\n",
            "Id: 426 - Question Length: 45 - context Length: 56151\n",
            "Id: 427 - Question Length: 88 - context Length: 41601\n",
            "Id: 428 - Question Length: 113 - context Length: 86389\n",
            "Id: 429 - Question Length: 39 - context Length: 22368\n",
            "Id: 430 - Question Length: 80 - context Length: 57896\n",
            "Id: 431 - Question Length: 114 - context Length: 5022\n",
            "Id: 432 - Question Length: 70 - context Length: 8883\n",
            "Id: 433 - Question Length: 133 - context Length: 63498\n",
            "Id: 434 - Question Length: 59 - context Length: 7466\n",
            "Id: 435 - Question Length: 46 - context Length: 45961\n",
            "Id: 436 - Question Length: 45 - context Length: 28355\n",
            "Id: 437 - Question Length: 59 - context Length: 5767\n",
            "Id: 438 - Question Length: 85 - context Length: 52619\n",
            "Id: 439 - Question Length: 64 - context Length: 7338\n",
            "Id: 440 - Question Length: 37 - context Length: 4491\n",
            "Id: 441 - Question Length: 54 - context Length: 78199\n",
            "Id: 442 - Question Length: 65 - context Length: 24848\n",
            "Id: 443 - Question Length: 102 - context Length: 23289\n",
            "Id: 444 - Question Length: 81 - context Length: 137631\n",
            "Id: 445 - Question Length: 143 - context Length: 149103\n",
            "Id: 446 - Question Length: 116 - context Length: 209875\n",
            "Id: 447 - Question Length: 55 - context Length: 6126\n",
            "Id: 448 - Question Length: 69 - context Length: 37003\n",
            "Id: 449 - Question Length: 50 - context Length: 81511\n",
            "Id: 450 - Question Length: 57 - context Length: 25959\n",
            "Id: 451 - Question Length: 44 - context Length: 13684\n",
            "Id: 452 - Question Length: 104 - context Length: 29367\n",
            "Id: 453 - Question Length: 92 - context Length: 4769\n",
            "Id: 454 - Question Length: 86 - context Length: 71221\n",
            "Id: 455 - Question Length: 35 - context Length: 4274\n",
            "Id: 456 - Question Length: 80 - context Length: 9343\n",
            "Id: 457 - Question Length: 76 - context Length: 61613\n",
            "Id: 458 - Question Length: 67 - context Length: 82304\n",
            "Id: 459 - Question Length: 80 - context Length: 5080\n",
            "Id: 460 - Question Length: 76 - context Length: 98309\n",
            "Id: 461 - Question Length: 35 - context Length: 45185\n",
            "Id: 462 - Question Length: 28 - context Length: 142270\n",
            "Id: 463 - Question Length: 45 - context Length: 51090\n",
            "Id: 464 - Question Length: 52 - context Length: 4424\n",
            "Id: 465 - Question Length: 43 - context Length: 54079\n",
            "Id: 466 - Question Length: 77 - context Length: 24815\n",
            "==============================\n",
            "\n",
            "\n",
            "Num examples larger than 4 * 4096 characters: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(schema: {'question': 'string', 'context': 'string', 'targets': 'list<item: string>', 'norm_target': 'string'}, num_rows: 114)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5MyFEZqzwZ-",
        "colab_type": "text"
      },
      "source": [
        "Interesting! We can see that only 114 examples have less than 4 * 4096 = 16384 characters...\n",
        "\n",
        "Most examples seem to have a very long context which will have to be cut to Longformer's maximum length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDPrsXOTV6R2",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "It's time to evaluate *Longformer* on *TriviaQA* ðŸš€.\n",
        "\n",
        "Let's write our evaluation function and import the pretrained `LongformerForQuestionAnswering` model. For more details on `LongformerForQuestionAnswering`, see [here](https://huggingface.co/transformers/model_doc/longformer.html?highlight=longformerforquestionanswering#transformers.LongformerForQuestionAnswering)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgcdBt41gby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import LongformerTokenizerFast, LongformerForQuestionAnswering\n",
        "\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")\n",
        "\n",
        "# download the 1.7 GB pretrained model. It might take ~1min\n",
        "model = LongformerForQuestionAnswering.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "def evaluate(example):\n",
        "    def get_answer(question, context):\n",
        "        # encode question and context so that they are seperated by a tokenizer.sep_token and cut at max_length\n",
        "        encoding = tokenizer.encode_plus(question, context, return_tensors=\"pt\", max_length=4096)\n",
        "        input_ids = encoding[\"input_ids\"].to(\"cuda\")\n",
        "        attention_mask = encoding[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "        # the forward method will automatically set global attention on question tokens\n",
        "        # The scores for the possible start token and end token of the answer are retrived\n",
        "        # wrap the function in torch.no_grad() to save memory\n",
        "        with torch.no_grad():\n",
        "            start_scores, end_scores = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Let's take the most likely token using `argmax` and retrieve the answer\n",
        "        all_tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"][0].tolist())\n",
        "        answer_tokens = all_tokens[torch.argmax(start_scores): torch.argmax(end_scores)+1]\n",
        "        answer = tokenizer.decode(tokenizer.convert_tokens_to_ids(answer_tokens))[1:].replace('\"', '')  # remove space prepending space token and remove unnecessary '\"'\n",
        "        \n",
        "        return answer\n",
        "\n",
        "    # save the model's output here\n",
        "    example[\"output\"] = get_answer(example[\"question\"], example[\"context\"])\n",
        "\n",
        "    # save if it's a match or not\n",
        "    example[\"match\"] = (example[\"output\"] in example[\"targets\"]) or (example[\"output\"] == example[\"norm_target\"])\n",
        "\n",
        "    return example\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh65UMh8WP2I",
        "colab_type": "text"
      },
      "source": [
        "We are interested in the performance of the model on short and long samples.\n",
        "First we evaluate the model on `short_validation_dataset`, which comprises only the samples that are shorter than 4 * 4096 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2REN9qH4HR2",
        "colab_type": "code",
        "outputId": "506d0fe5-b2eb-4245-f940-7375097337eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results_short = results_short.map(evaluate)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "114it [00:00, 12381.87it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULyIPLZIbtIP",
        "colab_type": "text"
      },
      "source": [
        "Now let's check for how many questions we were correct!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kavPCIWKWzua",
        "colab_type": "code",
        "outputId": "5b2ff4a9-a5df-42ba-c99c-72c916dea6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "print(f\"\\nNum Correct examples: {sum(results_short['match'])}/{len(results_short)}\")\n",
        "wrong_results = results_short.filter(lambda x: x['match'] is False)\n",
        "print(f\"\\nWrong examples: \")\n",
        "wrong_results.map(lambda x, i: print(f\"{i} - Output: {x['output']} - Target: {x['norm_target']}\"), with_indices=True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 135.22it/s]\n",
            "46it [00:00, 5004.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num Correct examples: 68/114\n",
            "\n",
            "Wrong examples: \n",
            "0 - Output: Doctor Finlay - Target: dr finlay\n",
            "0 - Output: Doctor Finlay - Target: dr finlay\n",
            "0 - Output: Doctor Finlay - Target: dr finlay\n",
            "1 - Output: film industry - Target: film making\n",
            "2 - Output: kaleidoscopes - Target: kaleidoscope\n",
            "3 - Output: fruit and vegetables - Target: fruit\n",
            "4 - Output:  - Target: motel 6\n",
            "5 - Output:  - Target: fiddler on roof\n",
            "6 - Output:  - Target: mutiny on bounty\n",
            "7 - Output: Tom Stoppard - Target: j g ballard\n",
            "8 - Output: Kentuckian - Target: kentuckian\n",
            "9 - Output: Roald Amundsen and his party on December 14, 1911. Amundsen named his camp Polheim and the entire plateau surrounding the Pole King Haakon VII Vidde in honour of King Haakon VII of Norway. Robert Falcon Scott returned to Antarctica with his second expedition, the Terra Nova Expedition, initially unaware of Amundsen's secretive expedition. Scott and four other men reached the South Pole on January 17, 1912, thirty-four days after Amundsen. On the return trip, Scott and his four companions all died of starvation and extreme cold.  In 1914 Ernest Shackleton's Imperial Trans-Antarctic Expedition set out with the goal of crossing Antarctica via the South Pole, but his ship, the Endurance, was frozen in pack ice and sank 11 months later. The overland journey was never made.  US Admiral Richard Evelyn Byrd, with the assistance of his first pilot Bernt Balchen, became the first person to fly over the South Pole on November 29, 1928.  1950â€“present  It was not until 31 October 1956 that humans once again set foot at the South Pole, when a party led by Admiral George J. Dufek of the US Navy landed there in an R4D-5L Skytrain (C-47 Skytrain) aircraft. The US Amundsen-Scott South Pole Station was established by air over 1956â€“1957 for the International Geophysical Year and has been continuously staffed since then by research and support personnel.  After Amundsen and Scott, the next people to reach the South Pole overland (albeit with some air support) were Edmund Hillary - Target: edmond hillary\n",
            "10 - Output:  - Target: all in family\n",
            "11 - Output: Roy Orbison - Target: donny osmond\n",
            "12 - Output: Lisa Kudrow - Target: jennifer aniston\n",
            "13 - Output:  - Target: george\n",
            "14 - Output: Bette Davis and Joan Crawford - Target: crawford\n",
            "15 - Output: La Grange - Target: chicken ranch\n",
            "16 - Output:  - Target: belgium\n",
            "17 - Output: 1936â€“46 - Target: 13\n",
            "18 - Output: Gary Lewis - Target: gary lewis and playboys\n",
            "19 - Output: Collapsible baby buggy - Target: baby buggy\n",
            "20 - Output:  - Target: basket ball\n",
            "21 - Output: sprint canoeist - Target: canoeing\n",
            "22 - Output: Jon Bon Jovi - Target: presley\n",
            "23 - Output: Cora Crippen - Target: his wife\n",
            "24 - Output: jingoism - Target: chauvinism\n",
            "25 - Output: muscle - Target: muscle tissue\n",
            "26 - Output: testes - Target: corpus luteum\n",
            "27 - Output: 11 - Target: 11 years and 302 days\n",
            "28 - Output: Nicholas Nick Berry - Target: nick berry\n",
            "29 - Output: File:Ido2.JPG|Istanbul - Target: istanbul\n",
            "30 - Output: horse racing - Target: horseracing\n",
            "31 - Output: Christmas Carol - Target: christmas carol\n",
            "32 - Output: Cliff Richard - Target: beatles\n",
            "33 - Output: Neruda - Target: pablo neruda\n",
            "34 - Output:  - Target: razor\n",
            "35 - Output: Geena Davis and Hugh Laurie star as Eleanor and Frederick Little, with Jonathan Lipnicki as Stuart's big brother George Little and Nathan Lane as the voice of the family cat Snowbell.  The film was released on December 17, 1999, by Columbia Pictures.  It received an Academy Award for Best Visual Effects nomination, but lost to The Matrix. The film, the first in the film series, spawned a sequel in 2002, Stuart Little 2, the short-lived TV show Stuart Little: The Animated Series in 2003, and another sequel in 2005, the animated direct-to-video Stuart Little 3: Call of the Wild.  This film was Estelle Getty's final film before her retirement in 2001 and her death in 2008.  Plot  Eleanor Little (Geena Davis - Target: geena davis\n",
            "36 - Output: Stuart - Target: house of dunkeld\n",
            "37 - Output:  - Target: hippety hopper\n",
            "38 - Output: raspberries - Target: blackberry\n",
            "39 - Output:  - Target: windy miller\n",
            "40 - Output: *Christina Ricci - Target: christina ricci\n",
            "41 - Output: Switzerland - Target: st moritz\n",
            "42 - Output: beetles - Target: beetle\n",
            "43 - Output: Steptoe and Son, eight series of which were aired between 1962 and 1974.   Career  The partnership's break in comedy writing came with the Derek Roy vehicle Happy Go Lucky, although this was not a success.  The Hancock connection began with their involvement with later radio variety series, and from November 1954 continued with Hancock's Half Hour on radio; a series featuring their scripts for Hancock ran on television between 1956 and 1961. In October that year Hancock ended his professional relationship with the writers, and with Beryl Vertue who worked with the writers' at their agency Associated London Scripts. This writers' co-operative had been founded by Eric Sykes and Spike Milligan, with others involved, including Hancock for a time.   After their association with Hancock had ended, they wrote a series of Comedy Playhouse (1961â€“62), ten one-off half-hour plays for the BBC. One play in the series, The Offer, was well received, and from this emerged Steptoe and Son - Target: steptoe and son\n",
            "44 - Output: Frosted Flakes (also known as Frosties) breakfast cereal - Target: frosties\n",
            "45 - Output: gray - Target: purple\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(schema: {'question': 'string', 'context': 'string', 'targets': 'list<item: string>', 'norm_target': 'string', 'output': 'string', 'match': 'bool'}, num_rows: 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViCCSxzPc2Gk",
        "colab_type": "text"
      },
      "source": [
        "68/114 - not bad ðŸ”¥. Also we can see that many of the wrong outputs are very close to the correct solution or are the correct solution, but just written differently (Number 0,8, ...). One could obviously make a better post processing script that makes sure solutions like 0 and 8 are counted as correct solutions by adding a couple of lines to the `evaluate` function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Si1eo3tYBR_",
        "colab_type": "text"
      },
      "source": [
        "**Note**: *Longformer reached a new SOTA on TriviaQA - see Table 9 in [paper](https://arxiv.org/abs/2004.05150). In order to reproduce the exact results, please refer to the following [instructions](https://github.com/allenai/longformer/blob/master/scripts/cheatsheet.txt).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5CtQILEVMay",
        "colab_type": "text"
      },
      "source": [
        "Second, we evaluate `LongformerForQuestionAnswering` on the all of the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWNtljj3Wr9h",
        "colab_type": "code",
        "outputId": "63ea75c7-ec78-48d7-e301-ecd70b678b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results = validation_dataset.map(evaluate)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "467it [09:31,  1.22s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyDYG4YDXFV7",
        "colab_type": "code",
        "outputId": "a22aeea3-b95a-4743-af90-fa978a282f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"Correct examples: {sum(results['match'])}/{len(results)}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correct examples: 224/467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80MqFyP4JIj",
        "colab_type": "text"
      },
      "source": [
        "Here, we now see a slight degradation. Less than half the samples are correct. It is still a very good score though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suv6-Rb5Xe9X",
        "colab_type": "text"
      },
      "source": [
        "Now you should have all the tools necessary to preprocess your data and evaluate your model with ðŸ¤—nlp in no time!\n",
        "\n",
        "ðŸ¤— ðŸ¤— **Finish** ðŸ¤—ðŸ¤—\n",
        "\n",
        "Thanks goes out to Iz Beltagy for proof reading the notebook!"
      ]
    }
  ]
}